{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import torch, the main PyTorch library. It provides tensor computation (like NumPy) with strong GPU acceleration and deep neural networks built on a tape-based autograd system.\n",
        "import torch\n",
        "\n",
        "# Import nn module from PyTorch. This module provides a way to create and train neural networks. It includes a wide range of layer types, activation functions, and utilities for building deep learning models.\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import functional module from PyTorch. This module contains functions for operations used in building neural networks, like activation functions (e.g., relu, sigmoid), pooling operations, and loss functions.\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import optim module from PyTorch. This module includes various optimization algorithms for adjusting the parameters of your neural networks, such as SGD, Adam, etc.\n",
        "import torch.optim as optim\n",
        "\n",
        "# Import datasets and transforms from torchvision. 'torchvision' is a package in the PyTorch project that provides utilities for working with image data. It includes common datasets and transformations you can use to preprocess your data.\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# This command uses the pip package installer to install the torchsummary package. torchsummary provides a simple way to see the details of your PyTorch model, such as the number of parameters and the shape of the output at each layer.\n",
        "!pip install torchsummary\n",
        "\n",
        "# Import the summary function from the torchsummary package. This function is used to display the model architecture in a clear and concise manner, including information on the output shapes of each layer and the number of parameters.\n",
        "from torchsummary import summary\n"
      ],
      "metadata": {
        "id": "hnvKuT_IUX2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3580eda-8d32-45ab-81a5-29cfb6611985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the torch library to check for CUDA availability\n",
        "import torch\n",
        "\n",
        "# Check if CUDA is available on the system\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "# Set the device to CUDA if available, otherwise fall back to CPU\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# The 'device' variable now holds a reference to the device (GPU or CPU) where the computations will be performed.\n",
        "# This line, if executed, would simply output the type of device selected, showing 'cuda' for GPU or 'cpu' for CPU.\n",
        "# However, in a script, this line as standalone would not produce output without being printed or used in a computation.\n"
      ],
      "metadata": {
        "id": "s5eQdcf5UwKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the batch size for loading the data\n",
        "batch_size = 128\n",
        "\n",
        "# Create a DataLoader for the training data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    # Load the MNIST dataset. If it's not present locally, it will be downloaded.\n",
        "    # The dataset is set to training mode (train=True).\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    # Transform the data by converting images to PyTorch tensors and normalizing them.\n",
        "                    # Normalization uses mean=0.1307 and std=0.3081, which are derived from the MNIST dataset.\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),  # Convert images to PyTorch tensors.\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))  # Normalize images.\n",
        "                    ])),\n",
        "    batch_size=batch_size,  # Specify the batch size for the DataLoader.\n",
        "    shuffle=True)  # Shuffle the data every epoch to avoid model overfitting on the order of the data.\n",
        "\n",
        "# Create a DataLoader for the test data\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    # Load the MNIST dataset for testing (train=False indicates test set).\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),  # Convert images to PyTorch tensors.\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))  # Normalize images.\n",
        "                    ])),\n",
        "    batch_size=batch_size,  # Specify the batch size.\n",
        "    shuffle=True)  # Shuffle the test data to ensure random order during evaluation.\n"
      ],
      "metadata": {
        "id": "cibV-QyWU7ey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c5a615-276d-4f33-b0b0-e0b8b5ab3426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 90412052.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 84888362.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 30724595.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13156442.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Notes on our naive model\n",
        "\n",
        "We are going to write a network based on what we have learnt so far.\n",
        "\n",
        "The size of the input image is 28x28x1. We are going to add as many layers as required to reach RF = 32 \"atleast\"."
      ],
      "metadata": {
        "id": "r3gEjf-xMb-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstDNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FirstDNN, self).__init__()\n",
        "    # r_in:1, n_in:28, j_in:1, s:1, r_out:3, n_out:28, j_out:1\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "    # r_in:3 , n_in:28 , j_in:1 , s:1 , r_out:5 , n_out:28 , j_out:1\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    # r_in5: , n_in:28 , j_in:1 , s:2 , r_out:6 , n_out:14 , j_out:2\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    # r_in:6 , n_in:14 , j_in:2 , s:1 , r_out:10 , n_out:14 , j_out:2\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    # r_in:10 , n_in:14 , j_in:2 , s:1 , r_out:14 , n_out:14 , j_out:2\n",
        "    self.conv4 = nn.Conv2d(128, 256, 3, padding = 1)\n",
        "    # r_in:14 , n_in:14 , j_in:2 , s:2 , r_out:16 , n_out:7 , j_out:4\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    # r_in:16 , n_in:7 , j_in: 4, s:1 , r_out:32 , n_out:3 , j_out:4\n",
        "    self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "    # r_in:24 , n_in:5 , j_in:4 , s:1 , r_out:32 , n_out:3 , j_out:4\n",
        "    self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "    # r_in:32 , n_in:3 , j_in:4 , s:1 , r_out:40 , n_out:1 , j_out:4\n",
        "    self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "# Correct values\n",
        "# https://user-images.githubusercontent.com/498461/238034116-7db4cec0-7738-42df-8b67-afa971428d39.png\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "    x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "    x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "    x = self.conv7(x)\n",
        "   #x = F.relu(x) # this is the last step. Think what ReLU does to our results at this stage!\n",
        "    x = x.view(-1, 10)\n",
        "    return F.log_softmax(x)\n"
      ],
      "metadata": {
        "id": "Sir2LmSVLr_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstDNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FirstDNN, self).__init__()\n",
        "    # Initializes the parent class (nn.Module), essential for using PyTorch's model functionalities.\n",
        "\n",
        "    # First convolutional layer: 1 input channel, 32 output channels, kernel size 3x3, padding to keep output size.\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "\n",
        "    # Second convolutional layer: Increases depth to 64, kernel size 3x3, padding to keep output size.\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "\n",
        "    # First pooling layer: Reduces spatial dimensions by half, using 2x2 pooling window with stride 2.\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # Third convolutional layer: Increases depth to 128, kernel size 3x3, padding to keep output size.\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "\n",
        "    # Fourth convolutional layer: Increases depth to 256, kernel size 3x3, padding to keep output size.\n",
        "    self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "\n",
        "    # Second pooling layer: Further reduces spatial dimensions by half, using 2x2 pooling window with stride 2.\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # Fifth convolutional layer: Increases depth to 512, kernel size 3x3, no padding, reducing output size.\n",
        "    self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "\n",
        "    # Sixth convolutional layer: Increases depth to 1024, kernel size 3x3, no padding, maintaining output size.\n",
        "    self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "\n",
        "    # Seventh (final) convolutional layer: Reduces depth to match number of classes (10), kernel size 3x3, no padding.\n",
        "    self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "  def forward(self, x):\n",
        "    # Applies the first convolutional layer followed by ReLU activation function.\n",
        "    x = F.relu(self.conv1(x))\n",
        "    # Applies the second convolutional layer followed by ReLU and then the first pooling layer.\n",
        "    x = self.pool1(F.relu(self.conv2(x)))\n",
        "\n",
        "    # Applies the third and fourth convolutional layers with ReLU in between and ends with the second pooling layer.\n",
        "    x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "\n",
        "    # Applies the fifth and sixth convolutional layers with ReLU activation function in between.\n",
        "    x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "\n",
        "    # Applies the final, seventh convolutional layer. No ReLU here as it's right before the output layer.\n",
        "    x = self.conv7(x)\n",
        "\n",
        "    # Reshapes (flattens) the output to match the expected format for log_softmax, preparing for classification.\n",
        "    x = x.view(-1, 10)\n",
        "\n",
        "    # Applies the log_softmax function on the output, which is common for classification tasks.\n",
        "    return F.log_softmax(x, dim=-1)  # Added 'dim=-1' to specify the dimension over which softmax is applied."
      ],
      "metadata": {
        "id": "IfIu8ir_Nh0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "kFrFKrdZNjHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FirstDNN().to(device)"
      ],
      "metadata": {
        "id": "sxICO4TTNt2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M__MtFIYNwXa",
        "outputId": "f17d98a9-27aa-4ce7-8719-7c67b2e2d620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()  # Sets the model to training mode (affects dropout, batch normalization, etc.).\n",
        "\n",
        "    pbar = tqdm(train_loader)  # Wraps the data loader with a progress bar.\n",
        "    for batch_idx, (data, target) in enumerate(pbar):  # Loops over batches of data.\n",
        "        data, target = data.to(device), target.to(device)  # Moves data and target tensors to the specified device (CPU or GPU).\n",
        "\n",
        "        optimizer.zero_grad()  # Clears the gradients of all optimized tensors to prevent accumulation from previous iterations.\n",
        "\n",
        "        output = model(data)  # Feeds the input data through the model to get the output predictions.\n",
        "\n",
        "        loss = F.nll_loss(output, target)  # Calculates the loss using negative log likelihood loss between predictions and actual targets.\n",
        "\n",
        "        loss.backward()  # Computes the gradient of the loss w.r.t. model parameters.\n",
        "\n",
        "        optimizer.step()  # Updates the model parameters based on gradients.\n",
        "\n",
        "        pbar.set_description(desc=f'loss={loss.item()} batch_id={batch_idx}')  # Updates the progress bar with the current loss.\n"
      ],
      "metadata": {
        "id": "UP3hv-szN6wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()  # Sets the model to evaluation mode (affects dropout, batch normalization, etc.).\n",
        "\n",
        "    test_loss = 0  # Initializes the total test loss to 0.\n",
        "    correct = 0  # Initializes the count of correct predictions to 0.\n",
        "\n",
        "    with torch.no_grad():  # Disables gradient calculation to save memory and computations, since gradients are not needed for evaluation.\n",
        "        for data, target in test_loader:  # Loops over batches of test data.\n",
        "            data, target = data.to(device), target.to(device)  # Moves data and target tensors to the specified device.\n",
        "\n",
        "            output = model(data)  # Feeds the input data through the model to get the output predictions.\n",
        "\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # Sums up the loss for each batch.\n",
        "\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Finds the predicted class with the highest probability.\n",
        "\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()  # Counts the number of correct predictions.\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)  # Calculates the average loss per data point.\n",
        "\n",
        "    # Prints the test set's average loss and accuracy.\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n"
      ],
      "metadata": {
        "id": "-pohxDWgN-ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the optimizer with specific parameters for the model's training process.\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# optim.SGD: Stochastic Gradient Descent optimizer.\n",
        "# model.parameters(): Collects all trainable parameters of the model for optimization.\n",
        "# lr=0.01: Learning rate, determining the step size at each iteration to minimize the loss function.\n",
        "# momentum=0.9: Momentum helps accelerate gradients vectors in the right directions, thus leading to faster converging.\n",
        "\n",
        "# Start a loop to train and test the model across a specified number of epochs (cycles through the full dataset).\n",
        "for epoch in range(1, 3):\n",
        "    # epoch: Current iteration number out of the total specified iterations.\n",
        "\n",
        "    # Call the train function for the current epoch, passing the model, device (CPU or GPU), training data, optimizer, and epoch number.\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # train(...) function: Trains the model using the provided training data and updates the model's weights using the optimizer.\n",
        "\n",
        "    # Evaluate the model's performance on the test dataset after training.\n",
        "    test(model, device, test_loader)\n",
        "    # test(...) function: Tests the trained model using a separate dataset not seen by the model during the training phase to evaluate its performance.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0FYVWkGOFBS",
        "outputId": "7cff2e66-971f-4801-d4ee-30a7c7d72563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.062166977673769 batch_id=468: 100%|██████████| 469/469 [00:33<00:00, 14.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0643, Accuracy: 9791/10000 (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.07963237166404724 batch_id=468: 100%|██████████| 469/469 [00:31<00:00, 14.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0417, Accuracy: 9864/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6agTEkqzz6TZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}